<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>TensorFlow Studies</title><link>https://github.com/necromuralist/tensorflow_studies/</link><description>Notes as I study tensorflow.</description><atom:link href="https://github.com/necromuralist/tensorflow_studies/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 06 Jun 2018 00:05:25 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Training A Non-Neural Net Model</title><link>https://github.com/necromuralist/tensorflow_studies/posts/training-a-non-neural-net-model/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-org646280d" class="outline-2"&gt;
&lt;h2 id="org646280d"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org646280d"&gt;
&lt;p&gt;
This is the tensorflow style guide recommendation to make the code backwards-compatible with python 2.7. I don't think it makes sense here, since I don't use python 0 and python 2 is nearing the for-real-this-time end-of-life date (sometime in 2010) so I don't think I will, but I guess it's a safer practice. Oh, well.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;absolute_import&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python standard library&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="c1"&gt;# from pypi&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"axes.grid"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org623b1a8" class="outline-2"&gt;
&lt;h2 id="org623b1a8"&gt;A Polynomial Loss Model&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org623b1a8"&gt;
&lt;p&gt;
We're going to build a model using a polynomial loss function. Here's what it looks like.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Loss Function"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://github.com/necromuralist/tensorflow_studies/posts/training-a-non-neural-net-model/polynomial_loss.png" alt="polynomial_loss.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9b7cb1b" class="outline-3"&gt;
&lt;h3 id="org9b7cb1b"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9b7cb1b"&gt;
&lt;p&gt;
The first thing we will do is setup some variables for the training. The &lt;a href="https://www.tensorflow.org/programmers_guide/variables"&gt;&lt;code&gt;tensorflow.Variable&lt;/code&gt;&lt;/a&gt; is a tensor (but not a &lt;a href="https://www.tensorflow.org/programmers_guide/tensors"&gt;&lt;code&gt;tensorflow.Tensor&lt;/code&gt;&lt;/a&gt;) whose values can be updated. It maintains its value in between &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session"&gt;Sessions&lt;/a&gt; so if you run multiple sessions the value wil carry over to each run. Its constructor takes these arguments.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Default&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;initial_value&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Tensor that represents the starting value&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;trainable&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;If True, added to the collection of variables used by the Optimizers&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;collections&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;List of graph collection keys that the variable gets added to&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;validate_shape&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;If True, the shape of &lt;code&gt;initial_value&lt;/code&gt; must be known&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;caching_device&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Device string describing where to cache the Variable&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Name for the variable&lt;/td&gt;
&lt;td class="org-left"&gt;Variable + unique string&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;variable_def&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Protocol buffer to use to recreate a variable&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;dtype&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;If set, the &lt;code&gt;initial_value&lt;/code&gt; will be converted to it&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;expected_shape&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;If set, &lt;code&gt;initial_value&lt;/code&gt; should have this shape&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;import_scope&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Name scope to add if initializing from a protocol buffer&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;code&gt;constraint&lt;/code&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Optional function to apply after being updated by an Optimizer&lt;/td&gt;
&lt;td class="org-left"&gt;None&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
First we'll make a trainable variable with an initial value of 0. This is what we'll give to the loss function.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga123b19" class="outline-4"&gt;
&lt;h4 id="orga123b19"&gt;Variables&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga123b19"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x_variable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Next we'll make an un-trainable variable that holds the count of the number of times the model was trained..
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;step_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trainable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"stepCounter"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6ac9baf" class="outline-4"&gt;
&lt;h4 id="org6ac9baf"&gt;Loss Function&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6ac9baf"&gt;
&lt;p&gt;
We're going to use the same polynomial that I plotted above but defined using TensorFlow instead of numpy.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Express loss in terms of the variable&lt;/span&gt;
&lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_variable&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_variable&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;3.0&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_variable&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;4.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0eeec7b" class="outline-4"&gt;
&lt;h4 id="org0eeec7b"&gt;The Optimizer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0eeec7b"&gt;
&lt;p&gt;
TensorFlow uses &lt;a href="https://www.tensorflow.org/api_guides/python/train"&gt;&lt;code&gt;optimizers&lt;/code&gt;&lt;/a&gt; to train the model. In this case we know there's only one solution to minimize our loss function so we can use &lt;a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent"&gt;Stochastic Gradient Descent&lt;/a&gt; which is provided by &lt;a href="https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer"&gt;&lt;code&gt;tensorflow.training.GradientDescentOptimizer&lt;/code&gt;&lt;/a&gt;. It takes three arguments.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;learning&lt;sub&gt;rate&lt;/sub&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;How 'fast' it updates its values&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;use&lt;sub&gt;locking&lt;/sub&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;If True uses locks when updating&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;An identifier for debugging&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;

&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"GradientDescent"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
After we define the object we have to call the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#minimize"&gt;minimize&lt;/a&gt; function that returns a &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Operation"&gt;&lt;code&gt;tensorflow.Operation&lt;/code&gt;&lt;/a&gt; that will update the variable and update our step-counter everytime it's called.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;optimizer_operation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;step_counter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org149b523" class="outline-4"&gt;
&lt;h4 id="org149b523"&gt;Setup the training session&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org149b523"&gt;
&lt;p&gt;
First we have to initialize the variables. There are several ways to do this, the simplest is &lt;a href="https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer"&gt;&lt;code&gt;tensorflow.global_variables_initializer&lt;/code&gt;&lt;/a&gt;. This will return a &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Operation"&gt;&lt;code&gt;tensorflow.Operation&lt;/code&gt;&lt;/a&gt; that will initialize the variables when passed to the session to run.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
We want the variables to be persistent so we start up the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver"&gt;&lt;code&gt;tensorflow.train.Saver&lt;/code&gt;&lt;/a&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;saver&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Saver&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
We also want a summary and some logging so we can set that up here. First the summary.
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar"&gt;&lt;code&gt;tensorflow.summary.scalar&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter"&gt;&lt;code&gt;tensorflow.summary.FileWriter&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/get_default_graph"&gt;&lt;code&gt;tensorflow.get_default_graph&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;summary_operation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_variable&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;file_writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FileWriter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'log'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_default_graph&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now the logging.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_verbosity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Finally we get to the training session. We're going to re-train it 50 times (each training run is called an &lt;i&gt;epoch&lt;/i&gt;).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;losses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;summary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
	    &lt;span class="n"&gt;optimizer_operation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;step_counter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;x_variable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;summary_operation&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
	&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_every_n&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				       &lt;span class="s1"&gt;'Step &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;: Computed result = &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt; Loss: &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				       &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				       &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				       &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

	&lt;span class="n"&gt;file_writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;file_writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;saver&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'/output'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Final X: &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_variable&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
As you can see from the output, the result was reached fairly quickly.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"X Vs Epoch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"X"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Epoch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"loss"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"X"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;legend&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://github.com/necromuralist/tensorflow_studies/posts/training-a-non-neural-net-model/results.png" alt="results.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
Judging by the plot it reaches the minimum loss after less than 10 epochs.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>training tensorflow</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/training-a-non-neural-net-model/</guid><pubDate>Fri, 01 Jun 2018 20:23:09 GMT</pubDate></item><item><title>Logging, Summaries, and Saving Graphs</title><link>https://github.com/necromuralist/tensorflow_studies/posts/logging-multiple-graphs-summaries-and-saving-graphs/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;p&gt;
This is based on &lt;b&gt;TensorFlow for Dummies&lt;/b&gt; and the TensorFlow documentation.
&lt;/p&gt;

&lt;div id="outline-container-org9d23b9c" class="outline-2"&gt;
&lt;h2 id="org9d23b9c"&gt;What is this about?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9d23b9c"&gt;
&lt;p&gt;
This will demonstrate serveral things that might be commonly useful:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;How to use logging&lt;/li&gt;
&lt;li&gt;How to create multiple graphs&lt;/li&gt;
&lt;li&gt;How to summarize graphs&lt;/li&gt;
&lt;li&gt;How to save graphs to a file&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org628bcfa" class="outline-2"&gt;
&lt;h2 id="org628bcfa"&gt;How do you use logging?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org628bcfa"&gt;
&lt;p&gt;
The &lt;a href="https://www.tensorflow.org/api_docs/python/tf/logging"&gt;TensorFlow logging&lt;/a&gt; looks a lot like the regular &lt;a href="https://docs.python.org/3.5/library/logging.html"&gt;python logging&lt;/a&gt; with some notable helpful additions - you can have print conditionally, you can have it print only a certain number of times, and you can have it print once every so many times that it's called. To enable it you set its verbosity level with the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/logging/set_verbosity"&gt;set&lt;sub&gt;verbosity&lt;/sub&gt;&lt;/a&gt; function.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensorflow.logging.set_verbosity(tensorflow.logging.INFO)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8a281d0" class="outline-2"&gt;
&lt;h2 id="org8a281d0"&gt;Create some tensors&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8a281d0"&gt;
&lt;p&gt;
To actually illustrate how to use this stuff I'll create some tensors to do some linear algebra.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data_1 = tensorflow.random_normal([8], name="random")
data_2 = tensorflow.linspace(1.0, 100.0, 8, name="LinearSpace")
dot_product = tensorflow.tensordot(data_1, data_2, axes=1, name="DotProduct")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org32e8662" class="outline-2"&gt;
&lt;h2 id="org32e8662"&gt;How do you create summary information?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org32e8662"&gt;
&lt;p&gt;
There are basically two steps. For each of your Tensors, you add it using &lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar"&gt;&lt;code&gt;tensorflow.summary.scalar&lt;/code&gt;&lt;/a&gt;, then you merge the summaries into one using &lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/merge_all"&gt;=tensorflow.summary.merge&lt;sub&gt;all&lt;/sub&gt;&lt;/a&gt;. For my tensors created in the previous section it would look something like this.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensorflow.summary.scalar("data_1", data_1[0])
tensorflow.summary.scalar("data_2", data_2[0])
tensorflow.summary.scalar("dot_product", dot_product)

merged = tensorflow.summary.merge_all()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge02617e" class="outline-2"&gt;
&lt;h2 id="orge02617e"&gt;How do you save the summary?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge02617e"&gt;
&lt;p&gt;
You can save the summary as a &lt;a href="https://en.wikipedia.org/wiki/Protocol_Buffers"&gt;protocol buffer&lt;/a&gt; using &lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter"&gt;&lt;code&gt;tensorflow.summary.FileWriter&lt;/code&gt;&lt;/a&gt;. This next step will create it and then you use it once you run the session.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;writer = tensorflow.summary.FileWriter("/tmp/tensorlog", graph=tensorflow.get_default_graph())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
These are the arguments to the &lt;code&gt;FileWriter&lt;/code&gt; constructor.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;logdir&lt;/td&gt;
&lt;td class="org-left"&gt;Directory where the file will be saved&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;graph&lt;/td&gt;
&lt;td class="org-left"&gt;The graph to store&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;max&lt;sub&gt;queue&lt;/sub&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Size of the event queue&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;flush&lt;sub&gt;secs&lt;/sub&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;How often to flush pending items to disk&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;filename&lt;sub&gt;suffix&lt;/sub&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Suffix to add to the file&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf4fb65d" class="outline-2"&gt;
&lt;h2 id="orgf4fb65d"&gt;Okay, but how do you use this?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf4fb65d"&gt;
&lt;p&gt;
You run this in a session.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with tensorflow.Session() as session:
    # run the session
    outcome, summary = session.run([dot_product, merged])

    # log the outcome
    tensorflow.logging.info("Dot Product: %s", outcome)

    # print the summary
    writer.add_summary(summary)

    # force it to dump now
    writer.flush()

    # Save the graph
    tensorflow.train.write_graph(session.graph, "/tmp/tensorlog", 'graph_1.dat')
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
INFO:tensorflow:Dot Product: -77.974

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgbe73849" class="outline-3"&gt;
&lt;h3 id="orgbe73849"&gt;Come again?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbe73849"&gt;
&lt;p&gt;
In our previous code, we were setting up the code that we want to run. To actually run it you start a &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session"&gt;&lt;code&gt;tensorflow.Session&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session#run"&gt;run&lt;/a&gt; the operations in the graph (called &lt;code&gt;dot_product&lt;/code&gt; in this case). Since we want a summary, you also pass in the &lt;code&gt;merged&lt;/code&gt; summary. the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter#add_summary"&gt;&lt;code&gt;tensorflow.summary.FileWriter.add_summary&lt;/code&gt;&lt;/a&gt; method adds the summary protocol buffer to the file-writer and the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter#flush"&gt;&lt;code&gt;tensorflow.summary.FileWriter.flush&lt;/code&gt;&lt;/a&gt; method tells the FileWriter to write it to disk immediately instead of buffering it to memory. Finally the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/train/write_graph"&gt;&lt;code&gt;tensorflow.train.write_graph&lt;/code&gt;&lt;/a&gt; function stores the graph as a protocol buffer to disk.
&lt;/p&gt;

&lt;p&gt;
You may notice that there really isn't anything shown by the summary, it's just being dumped to disk. That's because you look at the summary using &lt;a href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"&gt;TensorBoard&lt;/a&gt;, which starts a web-server that lets you inspect the summary. You can pass it the directory where we stored the summary when you start it.
&lt;/p&gt;

&lt;pre class="example"&gt;
tensorflow --logdir /tmp/tensorlog
&lt;/pre&gt;

&lt;p&gt;
This will open a web-server at &lt;code&gt;http://localhost:6006&lt;/code&gt; where you can poke around at the graph.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>tensorflow dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/logging-multiple-graphs-summaries-and-saving-graphs/</guid><pubDate>Tue, 29 May 2018 21:30:05 GMT</pubDate></item><item><title>How Do You Create Tensors With Random Values?</title><link>https://github.com/necromuralist/tensorflow_studies/posts/how-do-you-create-tensors-with-random-values/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;p&gt;
Sometimes you want to initialize tensors with random values, like when you initialize a set of weights to train. You could start out with 0's or 1's but often when you don't know what values you want, it's better to start with random numbers. Here are the functions that tensorflow has.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Function&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/random_normal"&gt;&lt;code&gt;random_normal&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Outputs random values from the &lt;a href="https://en.wikipedia.org/wiki/Normal_distribution"&gt;normal distribution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/truncated_normal"&gt;&lt;code&gt;truncated_normal&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Values from the normal distribution within 2 standard deviations from the mean&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/random_uniform"&gt;&lt;code&gt;random_uniform&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Random values from a &lt;a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)"&gt;uniform distribution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/random_shuffle"&gt;&lt;code&gt;random_shuffle&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Randomly shuffles a tensor along its first dimension&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/random_crop"&gt;&lt;code&gt;random_crop&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Randomly crop a tensor to a given size&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/multinomial"&gt;&lt;code&gt;multinomial&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Random values from a &lt;a href="https://en.wikipedia.org/wiki/Multinomial_distribution"&gt;multinomial distribution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/random_gamma"&gt;&lt;code&gt;random_gamma&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Samples from each of the &lt;a href="https://en.wikipedia.org/wiki/Gamma_distribution"&gt;Gamma distributions&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/set_random_seed"&gt;&lt;code&gt;set_random_seed&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Sets the graph-level random seed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div id="outline-container-org1019add" class="outline-2"&gt;
&lt;h2 id="org1019add"&gt;How do you create a tensor with random values that are normally distributed?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1019add"&gt;
&lt;p&gt;
The &lt;code&gt;tenorflow.random_normal&lt;/code&gt; function creates a tensor of random value sampled from the normal distribution.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;shape&lt;/td&gt;
&lt;td class="org-left"&gt;The shape of the tensor to create&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;mean&lt;/td&gt;
&lt;td class="org-left"&gt;The center of the distribution&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;stddev&lt;/td&gt;
&lt;td class="org-left"&gt;The standard deviation of the distribution&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dtype&lt;/td&gt;
&lt;td class="org-left"&gt;The data type of the values&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;seed&lt;/td&gt;
&lt;td class="org-left"&gt;A python integer to set the random seed&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;A label for debugging&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
By default the &lt;code&gt;random_normal&lt;/code&gt; functions samples from the standard normal distribution (so it has a mean of 0 and a standard deviation of 1). Here's how to create a \(3 \times 3\) tensor with values from the standard normal distribution.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("random_normal:0", shape=(3, 3), dtype=float32)

&lt;/pre&gt;

&lt;p&gt;
If you want a different distribution you can pass in the mean and standard deviation. If you want to make it reproducible by others, you can also pass in the seed, althought the &lt;code&gt;set_random_seed&lt;/code&gt; function might be better for that.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Bob"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("Bob:0", shape=(3, 3), dtype=float32)

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge05bdb8" class="outline-3"&gt;
&lt;h3 id="orge05bdb8"&gt;How do you create a tensor with random values sampled from the normal distribution but not unlikely values?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge05bdb8"&gt;
&lt;p&gt;
Because about &lt;a href="https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule"&gt;95% of the area under the curve sits within 2 standard deviation from the mean&lt;/a&gt;, you can have tensorflow truncate the values that are more than 2 standard deviations from the mean so that you won't get those less likely values. This function takes the same arguments as the &lt;code&gt;random_normal&lt;/code&gt; function (so you can't change the truncation value).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"TrunkyMcTrunkface"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("TrunkyMcTrunkface:0", shape=(3, 3), dtype=float32)

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3eb2066" class="outline-2"&gt;
&lt;h2 id="org3eb2066"&gt;How do I make this randomness reproducible?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org3eb2066"&gt;
&lt;p&gt;
If you want to make the random values reproducible (by yourself or others) you can set the random seed using &lt;code&gt;set_random_seed&lt;/code&gt;. This will set the seed for the entire graph. There are two types of seeds to set - the graph-level seed (set here) that will be shared by all the operations and at the operation-level - by passing in the &lt;code&gt;seed&lt;/code&gt; argument to &lt;code&gt;random_normal&lt;/code&gt; for instance. You can use either or both, but I think in most cases you would want to use the &lt;code&gt;set_random_seed&lt;/code&gt; function unless you have a specific reason not to.
&lt;/p&gt;

&lt;p&gt;
To see this in action, I'll create two random uniform numbers and two random normal numbers.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Session 1"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_random_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;uniform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_uniform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;normal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Session 1
[0.3206401]
[0.012326]
[1.018752]
[-1.0647357]

&lt;/pre&gt;

&lt;p&gt;
Now we'll do this again but in a new session. This should restart the random-number generators, giving us the same 'random' numbers.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Session 2"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session_2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Session 2
[0.3206401]
[0.012326]
[1.018752]
[-1.0647357]

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc2e6dd0" class="outline-3"&gt;
&lt;h3 id="orgc2e6dd0"&gt;Does setting the seed have to come before creating the tensors?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc2e6dd0"&gt;
&lt;p&gt;
Let's try it and see.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Session 3"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;uniform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_uniform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;normal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_random_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session_3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Session 3
[0.16354513]
[0.8006109]
[-0.84182554]
[-2.697645]

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Session 4"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session_4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session_4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Session 4
[0.16354513]
[0.8006109]
[-0.84182554]
[-2.697645]

&lt;/pre&gt;

&lt;p&gt;
Since the numbers put out by both sessions are the same, the answer appears to be no. But wait, why does the second set of numbers not match the first? I'm assuming this is because I'm running this in a notebook I'll have to look into that more. According to &lt;a href="https://stackoverflow.com/questions/36096386/tensorflow-set-random-seed-not-working"&gt;Stack Overflow&lt;/a&gt; you either have to call &lt;code&gt;reset_default_graph&lt;/code&gt; or set it at the operation-level (i.e. pass in the seed when creating the tensor). Resetting the default graph didn't seem to work when I tried it, but we'll see, I'm not a researcher so this might not be something for me to deal with right now.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>tensorflow dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/how-do-you-create-tensors-with-random-values/</guid><pubDate>Tue, 29 May 2018 00:47:20 GMT</pubDate></item><item><title>How do you create a Tensor with constant values?</title><link>https://github.com/necromuralist/tensorflow_studies/posts/constant-value-tensors/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;p&gt;
These are notes from &lt;b&gt;TensorFlow for Dummies&lt;/b&gt; and the &lt;a href="https://www.tensorflow.org/api_guides/python/constant_op#Constant_Value_Tensors"&gt;tensorflow documentation&lt;/a&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sys.stderr = sys.stdout
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
There are various ways to create tensors by calling &lt;code&gt;tensorflow&lt;/code&gt; functions with values that you specify. I'll list some of the ways to create tensors with pre-specified values. The &lt;code&gt;Argument&lt;/code&gt; is just the main one you pass in to specify the tensor you want, each of the function has others as well, but they are optional. The &lt;code&gt;Returned Tensor Values&lt;/code&gt; describes what values are held by the tensor that is returned by the function.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;&lt;code&gt;tensorflow&lt;/code&gt; Function&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Returned Tensor Values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/constant"&gt;constant&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Value(s)&lt;/td&gt;
&lt;td class="org-left"&gt;the value(s) you gave&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/zeros"&gt;zeros&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Shape&lt;/td&gt;
&lt;td class="org-left"&gt;all zeros&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/ones"&gt;ones&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Shape&lt;/td&gt;
&lt;td class="org-left"&gt;All ones&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/fill"&gt;fill&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Shape, Value&lt;/td&gt;
&lt;td class="org-left"&gt;All the given value&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/lin-space"&gt;linspace&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Start, Stop, Steps&lt;/td&gt;
&lt;td class="org-left"&gt;linearly spaced floats within the given range&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/range"&gt;range&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Start, Limit, Delta&lt;/td&gt;
&lt;td class="org-left"&gt;range of numbers based on start, stop, and delta&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;div id="outline-container-orgd82404e" class="outline-2"&gt;
&lt;h2 id="orgd82404e"&gt;How do you create a tensor with a constant value or values in it?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd82404e"&gt;
&lt;p&gt;
This is how you would create a tensor whose values never change. These are the arguments &lt;code&gt;tensorflow.constant&lt;/code&gt; takes.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;value&lt;/td&gt;
&lt;td class="org-left"&gt;value or list of values for the tensor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dtype&lt;/td&gt;
&lt;td class="org-left"&gt;Type of the elements for the tensor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;shape&lt;/td&gt;
&lt;td class="org-left"&gt;Dimensions of the tensor to create&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;name for the tensor&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tensorflow.constant(3))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("Const:0", shape=(), dtype=int32)

&lt;/pre&gt;

&lt;p&gt;
Passing in the value and the shape seems unnecessary, but the more specific you are, the more built in error handling you have. To actually raise an error on a mismatch, though, you have to pass in an extra &lt;code&gt;True&lt;/code&gt; argument to turn on error checking. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;try:
    tensorflow.constant([1,3], tensorflow.int16, [3], 'Fail', True)
except TypeError as error:
    print(error)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Expected Tensor's shape: (3,), got (2,).

&lt;/pre&gt;

&lt;p&gt;
Another useful thing about the &lt;code&gt;shape&lt;/code&gt; argument is that if you pass in a single value and a shape, then it will create a tensor with the given shape and use the value you passed in to populate it. This would create a \(3 \times 2\) tensor with 5 for all the values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tensorflow.constant(5, shape=[3, 2]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("Const_6:0", shape=(3, 2), dtype=int32)

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org507eb51" class="outline-3"&gt;
&lt;h3 id="org507eb51"&gt;That's nice, but what do you do with it?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org507eb51"&gt;
&lt;p&gt;
The Tensor's we create are used to create a graph (there is one default one so as we create tensors we are adding them to this default graph). Then to actually do something we have to run them in a session. Here's how to do \(4 + 8\) in TensorFlow.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;four = tensorflow.constant(4, dtype=tensorflow.float32)
eight = tensorflow.constant(8, dtype=tensorflow.float32)
four_plus_eight = four + eight

with tensorflow.Session() as session:
    print(session.run(four_plus_eight))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
12.0

&lt;/pre&gt;

&lt;p&gt;
And here's how you do \(4 \times 8\).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;four_times_eight = four * eight
with tensorflow.Session() as session:
    print(session.run(four_times_eight))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
32.0

&lt;/pre&gt;

&lt;p&gt;
Excited?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbfd8891" class="outline-2"&gt;
&lt;h2 id="orgbfd8891"&gt;How do you create a tensor with only zeros or only ones in it?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgbfd8891"&gt;
&lt;p&gt;
For the &lt;code&gt;zeros&lt;/code&gt; and &lt;code&gt;ones&lt;/code&gt; functions you only have to pass in the shape, but it does have some other arguments.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;shape&lt;/td&gt;
&lt;td class="org-left"&gt;A list with the shape of the tensor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dtype&lt;/td&gt;
&lt;td class="org-left"&gt;The data-type you want the values to have&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;A descriptive name to make debugging easier&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Here's how to create a \(5 \times 6\) tensor filled with zeros.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;zeros = tensorflow.zeros([5, 6])
print(zeros)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("zeros_1:0", shape=(5, 6), dtype=float32)

&lt;/pre&gt;

&lt;p&gt;
Here's how to create a tensor with the same shape but filled with ones.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ones = tensorflow.ones([5, 6])
print(ones)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("ones_2:0", shape=(5, 6), dtype=float32)

&lt;/pre&gt;

&lt;p&gt;
These are really convenience functions that do the same thing as the &lt;code&gt;constant&lt;/code&gt; function. Since I'm  creating Tensors, you can use the operations on them as I did earlier.
&lt;/p&gt;

&lt;p&gt;
If you multiply the ones by a scalar it will transmit it across the cells.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with tensorflow.Session() as session:
    print(session.run(four * ones))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]]

&lt;/pre&gt;

&lt;p&gt;
Since 0 is the identifier for addition we can do a similar thing to the zeros.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with tensorflow.Session() as session:
    print(session.run(four + zeros))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]
 [4. 4. 4. 4. 4. 4.]]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb28fa1c" class="outline-2"&gt;
&lt;h2 id="orgb28fa1c"&gt;How do you create a tensor filled with the same value?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgb28fa1c"&gt;
&lt;p&gt;
The &lt;code&gt;fill&lt;/code&gt; function creates a tensor with all the values and data-types being the same as the value you give it, so there's no &lt;code&gt;dtype&lt;/code&gt; argument. I'm not sure when this would be preferable to using &lt;code&gt;constant&lt;/code&gt;, maybe it's just a convenience function
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;dims&lt;/td&gt;
&lt;td class="org-left"&gt;The shape of the tensor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;value&lt;/td&gt;
&lt;td class="org-left"&gt;The value to fill the tensor with&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;Descriptive name for debugging&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The &lt;b&gt;Dummies&lt;/b&gt; book says that &lt;code&gt;fill&lt;/code&gt; only works with 32-bit floating point numbers, but that doesn't appear to be the case at the momemnt.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tensorflow.fill([5, 6], 5))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("Fill_1:0", shape=(5, 6), dtype=int32)

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgabbfab1" class="outline-2"&gt;
&lt;h2 id="orgabbfab1"&gt;How do you create a tensor of evenly spaced numbers?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgabbfab1"&gt;
&lt;p&gt;
The &lt;code&gt;linspace&lt;/code&gt; (linear space) function will create a tensor with numbers evenly spaced from some start value to some end value. The start and stop values you give it are always the first and last values in the tensor.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;start&lt;/td&gt;
&lt;td class="org-left"&gt;The first number in the sequence&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;stop&lt;/td&gt;
&lt;td class="org-left"&gt;The last number in the sequence&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;num&lt;/td&gt;
&lt;td class="org-left"&gt;The number of numbers in the sequence&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Here's how to create a tensor that represents a sequence from 5 to 13 with 7 numbers in the sequence.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tensorflow.linspace(5.0, 13.0, 7))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("LinSpace_12:0", shape=(7,), dtype=float32)

&lt;/pre&gt;


&lt;p&gt;
Note that the number types are important here. The &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;stop&lt;/code&gt; have to be floating point numbers (so use a decmal point) and them &lt;code&gt;num&lt;/code&gt; has to be an integer (so don't put a decimal point).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;try:
    tensorflow.linspace(5, 13, 7)
except TypeError as error:
    print(error)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Value passed to parameter 'start' has DataType int32 not in list of allowed values: bfloat16, float32, float64

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org74aa723" class="outline-2"&gt;
&lt;h2 id="org74aa723"&gt;How do you create a tensor with a range of numbers with a specific amount between each step?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org74aa723"&gt;
&lt;p&gt;
The &lt;code&gt;range&lt;/code&gt; function creates a tensor works similarly to &lt;a href="https://docs.python.org/3.5/library/functions.html#func-range"&gt;ipython's range&lt;/a&gt;, you give a start value, an upper limit value and a step-size (what &lt;b&gt;tensorflow&lt;/b&gt; calls a delta) and it creates values from the start up to the upper limit (but not including it).
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Argument&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;start&lt;/td&gt;
&lt;td class="org-left"&gt;The first number in the range&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;limit&lt;/td&gt;
&lt;td class="org-left"&gt;The upper bound for the range&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;delta&lt;/td&gt;
&lt;td class="org-left"&gt;The amount to add to each previous value to create the range&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dtype&lt;/td&gt;
&lt;td class="org-left"&gt;The data-type for the values in the range&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;name&lt;/td&gt;
&lt;td class="org-left"&gt;A label to make debugging easier&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;
This makes a range from 5 to 8 with steps of 2. By default it will use the data-type of the values you pass in, so I'll cast it to a float, just to be different.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tensorflow.range(5, 8, 2, dtype=tensorflow.float32, name="Ted"))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tensor("Ted_1:0", shape=(2,), dtype=float32)

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>tensorflow dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/constant-value-tensors/</guid><pubDate>Tue, 29 May 2018 00:43:55 GMT</pubDate></item><item><title>What is a tensor?</title><link>https://github.com/necromuralist/tensorflow_studies/posts/what-is-a-tensor/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;p&gt;
These are notes from &lt;b&gt;TensorFlow for Dummies&lt;/b&gt; and the &lt;a href="https://www.tensorflow.org/api_guides/python/constant_op#Constant_Value_Tensors"&gt;tensorflow documentation&lt;/a&gt;.
&lt;/p&gt;

&lt;div id="outline-container-org28b8e6a" class="outline-2"&gt;
&lt;h2 id="org28b8e6a"&gt;What are tensors?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org28b8e6a"&gt;
&lt;p&gt;
This is primarily about &lt;a href="https://www.tensorflow.org/programmers_guide/tensors"&gt;tensors&lt;/a&gt;. Although they have a specific mathematical meeting, when working with them it might be easier just to think of them as arrays. Although the tensors look a lot like &lt;a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html"&gt;numpy&lt;/a&gt; arrays, because TensorFlow defines all its parts before executing anything in a session, while more traditional python libraries like &lt;a href="http://www.numpy.org/"&gt;numpy&lt;/a&gt; execute each line, all your operations need to be done through tensorflow's &lt;a href="https://www.tensorflow.org/api_docs/python/"&gt;API&lt;/a&gt;, rather than any other python method.
&lt;/p&gt;
&lt;/div&gt;


&lt;div id="outline-container-orgb9e0eca" class="outline-3"&gt;
&lt;h3 id="orgb9e0eca"&gt;Okay, so what's a tensor, again?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb9e0eca"&gt;
&lt;p&gt;
A tensor is an abstraction that encompasses the things you learned about in Linear Algebra and physics.
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;A tensor with zero dimensions is a &lt;b&gt;scalar&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;A tensor with one dimension is a &lt;b&gt;vector&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;A tensor with two dimensions is a &lt;b&gt;matrix&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
A &lt;b&gt;tensorflow&lt;/b&gt; tensor:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;is an instance of the &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"&gt;Tensor&lt;/a&gt; class&lt;/li&gt;
&lt;li&gt;can have elements of type float, integer, string, or boolean, and all the elements of a tensor must be of the same type&lt;/li&gt;
&lt;li&gt;can be created and operated on using the tensorflow API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
&lt;b&gt;Some Jargon&lt;/b&gt;
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Term&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;b&gt;rank&lt;/b&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;The number of dimensions of a tensor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&lt;b&gt;shape&lt;/b&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;The length of each of a tensor's dimensions&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>tensorflow dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/what-is-a-tensor/</guid><pubDate>Sun, 27 May 2018 01:28:55 GMT</pubDate></item><item><title>Hello Tensorflow</title><link>https://github.com/necromuralist/tensorflow_studies/posts/hellow-tensorflow/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;p&gt;
This is largely from &lt;b&gt;TensorFlow for Dummies&lt;/b&gt;.
&lt;/p&gt;

&lt;div id="outline-container-org9a2616f" class="outline-2"&gt;
&lt;h2 id="org9a2616f"&gt;Hello&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9a2616f"&gt;
&lt;p&gt;
This is a &lt;a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program"&gt;hello-world&lt;/a&gt; for tensorflow, it will create a tensor with our message and then print it when the graph is executed.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org01e6745" class="outline-3"&gt;
&lt;h3 id="org01e6745"&gt;Import&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org01e6745"&gt;
&lt;p&gt;
We're just going to import &lt;a href="https://www.tensorflow.org/"&gt;tensorflow&lt;/a&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org569ec71" class="outline-3"&gt;
&lt;h3 id="org569ec71"&gt;Create the Tensor&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org569ec71"&gt;
&lt;p&gt;
We're going to use &lt;a href="https://www.tensorflow.org/api_docs/python/tf/string_join"&gt;&lt;code&gt;string_join&lt;/code&gt;&lt;/a&gt; which takes a lists of strings (it will consider each one a separate &lt;a href="https://www.tensorflow.org/programmers_guide/tensors"&gt;tensor&lt;/a&gt;) and creates a single &lt;a href="https://en.wikipedia.org/wiki/Tensor"&gt;tensor&lt;/a&gt; that we're going to store in the &lt;code&gt;message&lt;/code&gt; variable.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string_join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'Hello '&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'TensorFlow!'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb9a052f" class="outline-3"&gt;
&lt;h3 id="orgb9a052f"&gt;Running the Session&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb9a052f"&gt;
&lt;p&gt;
When you create a tensor it doesn't execute the calculations, it just defines what is going to be used to run the execution. To actually execute it you need to create a &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session"&gt;Session&lt;/a&gt; and then &lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session#run"&gt;run&lt;/a&gt; it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
: b'Hello TensorFlow!'
&lt;/pre&gt;

&lt;p&gt;
The first argument to &lt;code&gt;run&lt;/code&gt; can be any single graph element or list of graph elements that you want tensorflow to execute.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org23e5aa3" class="outline-2"&gt;
&lt;h2 id="org23e5aa3"&gt;Style&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org23e5aa3"&gt;
&lt;p&gt;
Google has a &lt;a href="https://www.tensorflow.org/community/style_guide"&gt;style guide&lt;/a&gt; specifically for TensorFlow. It says that you should follow the &lt;a href="https://pep8.readthedocs.io/en/release-1.7.x/"&gt;PEP 8&lt;/a&gt; style guide except where they think they know better. The exceptions are:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;2 spaces instead of 4 for indentation&lt;/li&gt;
&lt;li&gt;Make everything compatible with both python 2 and 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
This means that every file should have these imports in them:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;absolute_import&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
And you should use &lt;a href="https://pythonhosted.org/six/"&gt;six&lt;/a&gt; or something like it to make other compatibility changes.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>tensorflow dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/hellow-tensorflow/</guid><pubDate>Sat, 26 May 2018 22:45:39 GMT</pubDate></item><item><title>Bibliography</title><link>https://github.com/necromuralist/tensorflow_studies/posts/bibliography/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-org5734e19" class="outline-2"&gt;
&lt;h2 id="org5734e19"&gt;Books&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5734e19"&gt;
&lt;p&gt;
[B1] Scarpino, Matthew. Tensorflow for Dummies. 1st edition. Indianapolis, IN: John Wiley and Sons, 2018.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography tensorflow</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/bibliography/</guid><pubDate>Sat, 26 May 2018 20:49:14 GMT</pubDate></item><item><title>The Development of Machine Learning (as it relates to TensorFlow)</title><link>https://github.com/necromuralist/tensorflow_studies/posts/the-development-of-machine-learning/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-orgcbf2e04" class="outline-2"&gt;
&lt;h2 id="orgcbf2e04"&gt;A Brief Timeline&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgcbf2e04"&gt;
&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Year&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Person&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Event&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;1763&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Thomas_Bayes"&gt;Thomas Bayes&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances"&gt;The Underpinning of Bayes' Theorem&lt;/a&gt; is published&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1803&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Adrien-Marie_Legendre"&gt;Adrian-Marie Legendre&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Discovers the &lt;a href="https://en.wikipedia.org/wiki/Least_squares"&gt;method of least squares&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1894&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Francis_Galton"&gt;Francis Galton&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Uses &lt;a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean"&gt;regression to the mean&lt;/a&gt; to study inherited traits&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1943&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch"&gt;McCulloch&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch"&gt;Pitts&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Create the first &lt;a href="https://en.wikipedia.org/wiki/Artificial_neuron"&gt;artificial neuron&lt;/a&gt; model&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1957&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Frank_Rosenblatt"&gt;Frank Rosenblatt&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Creates the &lt;a href="https://en.wikipedia.org/wiki/Perceptron"&gt;perceptron&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1963&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Vladimir_Vapnik"&gt;Vapnik&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Alexey_Chervonenkis"&gt;Chervonenkis&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Invent the &lt;a href="https://en.wikipedia.org/wiki/Support_vector_machine"&gt;Support Vector Machine algorithm&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1965&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Alexey_Ivakhnenko"&gt;Ivakhnenko&lt;/a&gt; and Lapa&lt;/td&gt;
&lt;td class="org-left"&gt;Demonstrate &lt;a href="https://en.wikipedia.org/wiki/Multilayer_perceptron"&gt;multilayer perceptron&lt;/a&gt; with non-linear activation&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1980&lt;/td&gt;
&lt;td class="org-left"&gt;Kunihiko Fukushima&lt;/td&gt;
&lt;td class="org-left"&gt;Proposes the &lt;a href="https://en.wikipedia.org/wiki/Neocognitron"&gt;neocognitron&lt;/a&gt;, a multilayer neural network for image recognition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1974&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Paul_Werbos"&gt;Paul Werbos&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Uses &lt;a href="https://en.wikipedia.org/wiki/Backpropagation"&gt;backpropagation&lt;/a&gt; to train a &lt;a href="https://en.wikipedia.org/wiki/Artificial_neural_network"&gt;neural network&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1982&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/John_Hopfield"&gt;John Hopfield&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Developes the &lt;a href="https://en.wikipedia.org/wiki/Hopfield_network"&gt;Hopfield network&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1986&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Terry_Sejnowski"&gt;Sejnowski&lt;/a&gt; and Rosenberg&lt;/td&gt;
&lt;td class="org-left"&gt;Develop &lt;a href="https://en.wikipedia.org/wiki/NETtalk_(artificial_neural_network)"&gt;NETtalk&lt;/a&gt;, an Neural Network that learned how to pronounce words&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1998&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Yann_LeCun"&gt;Yann LeCun&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Trains a &lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network"&gt;Convolutional Neural Network&lt;/a&gt; (the LeNet-5) to recognize digits&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2002&lt;/td&gt;
&lt;td class="org-left"&gt;Collobert, Kavukcuoglu, and Farabet&lt;/td&gt;
&lt;td class="org-left"&gt;Release the &lt;a href="https://en.wikipedia.org/wiki/Torch_(machine_learning)"&gt;Torch framework&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2006&lt;/td&gt;
&lt;td class="org-left"&gt;Netflix&lt;/td&gt;
&lt;td class="org-left"&gt;Offers &lt;a href="https://en.wikipedia.org/wiki/Netflix_Prize"&gt;$1 Million prize&lt;/a&gt; to help with movie recommendations&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2014&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Ian_Goodfellow"&gt;Ian Goodfellow&lt;/a&gt;, et al.&lt;/td&gt;
&lt;td class="org-left"&gt;Invent &lt;a href="https://en.wikipedia.org/wiki/Generative_adversarial_network"&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2015&lt;/td&gt;
&lt;td class="org-left"&gt;Francis Chollet&lt;/td&gt;
&lt;td class="org-left"&gt;Releases &lt;a href="https://en.wikipedia.org/wiki/Keras"&gt;Keras&lt;/a&gt; for deep neural network development&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2015&lt;/td&gt;
&lt;td class="org-left"&gt;&lt;a href="https://en.wikipedia.org/wiki/Google_Brain"&gt;Google Brain&lt;/a&gt;&lt;/td&gt;
&lt;td class="org-left"&gt;Releases &lt;a href="https://en.wikipedia.org/wiki/TensorFlow"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org76afb4a" class="outline-2"&gt;
&lt;h2 id="org76afb4a"&gt;Sources&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org76afb4a"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Scarpino, Matthew. Tensorflow for Dummies. 1st edition. Indianapolis, IN: John Wiley and Sons, 2018.&lt;/li&gt;
&lt;li&gt;Timeline of Artificial Intelligence. Wikipedia, May 17, 2018. &lt;a href="https://en.wikipedia.org/w/index.php?title=Timeline_of_artificial_intelligence&amp;amp;oldid=841669863"&gt;https://en.wikipedia.org/w/index.php?title=Timeline_of_artificial_intelligence&amp;amp;oldid=841669863&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Timeline of Machine Learning - Wikipedia. Accessed May 26, 2018. &lt;a href="https://en.wikipedia.org/wiki/Timeline_of_machine_learning"&gt;https://en.wikipedia.org/wiki/Timeline_of_machine_learning&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>history machinelearning dummies</category><guid>https://github.com/necromuralist/tensorflow_studies/posts/the-development-of-machine-learning/</guid><pubDate>Sat, 26 May 2018 20:45:28 GMT</pubDate></item></channel></rss>